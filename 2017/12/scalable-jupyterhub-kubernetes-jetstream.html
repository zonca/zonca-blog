<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Deploy scalable Jupyterhub with Kubernetes on Jetstream | Andrea Zonca</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Deploy scalable Jupyterhub with Kubernetes on Jetstream" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Tested in June 2018 with Ubuntu 18.04 and Kubernetes 1.10 Updated in February 2018 with newer version of kubeadm-bootstrap, Kubernetes 1.9.2" />
<meta property="og:description" content="Tested in June 2018 with Ubuntu 18.04 and Kubernetes 1.10 Updated in February 2018 with newer version of kubeadm-bootstrap, Kubernetes 1.9.2" />
<link rel="canonical" href="https://zonca.dev/2017/12/scalable-jupyterhub-kubernetes-jetstream.html" />
<meta property="og:url" content="https://zonca.dev/2017/12/scalable-jupyterhub-kubernetes-jetstream.html" />
<meta property="og:site_name" content="Andrea Zonca" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-12-05T18:00:00-06:00" />
<script type="application/ld+json">
{"headline":"Deploy scalable Jupyterhub with Kubernetes on Jetstream","url":"https://zonca.dev/2017/12/scalable-jupyterhub-kubernetes-jetstream.html","dateModified":"2017-12-05T18:00:00-06:00","datePublished":"2017-12-05T18:00:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zonca.dev/2017/12/scalable-jupyterhub-kubernetes-jetstream.html"},"description":"Tested in June 2018 with Ubuntu 18.04 and Kubernetes 1.10 Updated in February 2018 with newer version of kubeadm-bootstrap, Kubernetes 1.9.2","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://zonca.dev/feed.xml" title="Andrea Zonca" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Andrea Zonca</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/consult/">Consulting</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Deploy scalable Jupyterhub with Kubernetes on Jetstream</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2017-12-05T18:00:00-06:00" itemprop="datePublished">
        Dec 5, 2017
      </time>
    </p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#jupyterhub">jupyterhub</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#jetstream">jetstream</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#gateways">gateways</a>
        
      
      </p>
    

      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/zonca/zonca-blog/tree/master/_posts/2017-12-05-scalable-jupyterhub-kubernetes-jetstream.md" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

    </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul>
  <li><strong>Tested in June 2018 with Ubuntu 18.04 and Kubernetes 1.10</strong></li>
  <li><strong>Updated in February 2018 with newer version of <code class="language-plaintext highlighter-rouge">kubeadm-bootstrap</code>, Kubernetes 1.9.2</strong></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>The best infrastructure available to deploy Jupyterhub at scale is Kubernetes. Kubernetes provides a fault-tolerant system to deploy, manage and scale containers. The Jupyter team released a recipe to deploy Jupyterhub on top of Kubernetes, <a href="https://zero-to-jupyterhub.readthedocs.io">Zero to Jupyterhub</a>. In this deployment both the hub, the proxy and all Jupyter Notebooks servers for the users are running inside Docker containers managed by Kubernetes.</p>

<p>Kubernetes is a highly sophisticated system, for smaller deployments (30/50 users, less then 10 servers), another option is to use the Docker Swarm mode, I covered this in a <a href="https://zonca.github.io/2017/10/scalable-jupyterhub-docker-swarm-mode.html">tutorial on how to deploy it on Jetstream</a>.</p>

<p>If you are not already familiar with Kubernetes, better first read the <a href="https://zero-to-jupyterhub.readthedocs.io/en/latest/tools.html">section about tools in Zero to Jupyterhub</a>.</p>

<p>In this tutorial we will be installing Kubernetes on 2 Ubuntu instances on the XSEDE Jetstream OpenStack-based cloud, configure permanent storage with the Ceph distributed filesystem and run the “Zero to Jupyterhub” recipe to install Jupyterhub on it.</p>

<h2 id="setup-two-virtual-machines">Setup two virtual machines</h2>

<p>First of all we need to create two Virtual Machines from the <a href="https://use.jetstream-cloud.org">Jetstream Atmosphere admin panel</a>I tested this on XSEDE Jetstream Ubuntu 16.04 image (with Docker pre-installed), for testing purposes “small” instances work, then they can be scaled up for production. You can name them <code class="language-plaintext highlighter-rouge">master_node</code> and <code class="language-plaintext highlighter-rouge">node_1</code> for example.
Make sure that port 80 and 443 are open to outside connections.</p>

<p>Then you can SSH into the first machine with your XSEDE username with <code class="language-plaintext highlighter-rouge">sudo</code> privileges.</p>

<h2 id="install-kubernetes">Install Kubernetes</h2>

<p>The “Zero to Jupyterhub” recipe targets an already existing Kubernetes cluster, for example on Google Cloud. However the Berkeley Data Science Education Program team, which administers one of the largest Jupyterhub deployments to date, released a set of scripts based on the <code class="language-plaintext highlighter-rouge">kubeadm</code> tool to setup Kubernetes from scratch.</p>

<p>This will install all the Kubernetes services and configure the <code class="language-plaintext highlighter-rouge">kubectl</code> command line tool for administering and monitoring the cluster and the <code class="language-plaintext highlighter-rouge">helm</code> package manager to install pre-packaged services.</p>

<p>SSH into the first server and follow the instructions at <a href="https://github.com/data-8/kubeadm-bootstrap">https://github.com/data-8/kubeadm-bootstrap</a> to “Setup a Master Node”
this will install a more recent version of Docker.</p>

<p>Once the initialization of the master node is completed, you should be able to check that several containers (pods in Kubernetes) are running:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>zonca@js-xxx-xxx:~/kubeadm-bootstrap$ sudo kubectl get pods --all-namespaces
NAMESPACE     NAME                                                    READY     STATUS    RESTARTS   AGE
kube-system   etcd-js-169-xx.jetstream-cloud.org                      1/1       Running   0          1m
kube-system   kube-apiserver-js-169-xx.jetstream-cloud.org            1/1       Running   0          1m
kube-system   kube-controller-manager-js-169-xx.jetstream-cloud.org   1/1       Running   0          1m
kube-system   kube-dns-6f4fd4bdf-nxxkh                                3/3       Running   0          2m
kube-system   kube-flannel-ds-rlsgb                                   1/1       Running   1          2m
kube-system   kube-proxy-ntmwx                                        1/1       Running   0          2m
kube-system   kube-scheduler-js-169-xx.jetstream-cloud.org            1/1       Running   0          2m
kube-system   tiller-deploy-69cb6984f-77nx2                           1/1       Running   0          2m
support       support-nginx-ingress-controller-k4swb                  1/1       Running   0          36s
support       support-nginx-ingress-default-backend-cb84895fb-qs9pp   1/1       Running   0          36s
</code></pre></div></div>

<p>Make also sure routing is working by accessing with your web browser the address of the Virtual Machine <code class="language-plaintext highlighter-rouge">js-169-xx.jetstream-cloud.org</code> and verify you are getting the error message <code class="language-plaintext highlighter-rouge">default backend - 404</code>.</p>

<p>Then SSH to the other server and set it up as a worker following the instructions in “Setup a Worker Node” at <a href="https://github.com/data-8/kubeadm-bootstrap">https://github.com/data-8/kubeadm-bootstrap</a>,</p>

<p>Once the setup is complete on the worker, log back in to the master and check that the worker joined Kubernetes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>zonca@js-169-xx:~/kubeadm-bootstrap$ sudo kubectl get nodes
NAME                             STATUS    ROLES     AGE       VERSION
js-168-yyy.jetstream-cloud.org   Ready     &lt;none&gt;    1m        v1.9.2
js-169-xx.jetstream-cloud.org    Ready     master    2h        v1.9.2
</code></pre></div></div>

<h2 id="setup-permanent-storage-for-kubernetes">Setup permanent storage for Kubernetes</h2>

<p>The cluster we just setup has no permament storage, so user data would disappear every time a container is killed.
We woud like to provide users with a permament home that would be available across all of the Kubernetes cluster, so that even if a user container spawns again on a different server, the data are available.</p>

<p>First we want to login again to Jetstream web interface and create 2 Volumes (for example 10 GB) and attach them one each to the master and to the first node, these will be automatically mounted on <code class="language-plaintext highlighter-rouge">/vol_b</code>, with no need of rebooting the servers.</p>

<p>Kubernetes has capability to provide Permanent Volumes but it needs a backend distributed file system. In this tutorial we will be using <a href="https://rook.io/">Rook</a> which sets up the Ceph distributed filesystem across the nodes.</p>

<p>We can first use Helm to install the Rook services (I ran my tests with <code class="language-plaintext highlighter-rouge">v0.6.1</code>):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo helm repo add rook-alpha https://charts.rook.io/alpha
sudo helm install rook-alpha/rook
</code></pre></div></div>

<p>Then check that the pods have started:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>zonca@js-xxx-xxx:~/kubeadm-bootstrap$ sudo kubectl get pods
NAME                            READY     STATUS    RESTARTS   AGE
rook-agent-2v86r                1/1       Running   0          1h
rook-agent-7dfl9                1/1       Running   0          1h
rook-operator-88fb8f6f5-tss5t   1/1       Running   0          1h
</code></pre></div></div>

<p>Once the pods have started we can actually configure the storage, copy this <a href="https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/blob/master/storage_rook/rook-cluster.yaml"><code class="language-plaintext highlighter-rouge">rook-cluster.yaml</code> file</a> to the master node. Better clone all of the repository as we will be using other files later.</p>

<p>The most important bits are:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">dataDirHostPath</code>: this is a folder to save the Rook configuration, we can set it to <code class="language-plaintext highlighter-rouge">/var/lib/rook</code></li>
  <li><code class="language-plaintext highlighter-rouge">storage: directories</code>: this is were data is stored, we can set this to <code class="language-plaintext highlighter-rouge">/vol_b</code> which is the default mount point of Volumes on Jetstream. This way we can more easily back those up or increase their size.</li>
  <li><code class="language-plaintext highlighter-rouge">versionTag</code>: make sure this is the same as your <code class="language-plaintext highlighter-rouge">rook</code> version (you can find it with <code class="language-plaintext highlighter-rouge">sudo helm ls</code>)</li>
</ul>

<p>Then run it with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl create -f rook-cluster.yaml
</code></pre></div></div>

<p>And wait for the services to launch:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>zonca@js-xxx-xxx:~/kubeadm-bootstrap$ sudo kubectl -n rook get pods
NAME                              READY     STATUS    RESTARTS   AGE
rook-api-68b87d48d5-xmkpv         1/1       Running   0          6m
rook-ceph-mgr0-5ddd685b65-kw9bz   1/1       Running   0          6m
rook-ceph-mgr1-5fcf599447-j7bpn   1/1       Running   0          6m
rook-ceph-mon0-g7xsk              1/1       Running   0          7m
rook-ceph-mon1-zbfqt              1/1       Running   0          7m
rook-ceph-mon2-c6rzf              1/1       Running   0          6m
rook-ceph-osd-82lj5               1/1       Running   0          6m
rook-ceph-osd-cpln8               1/1       Running   0          6m
</code></pre></div></div>

<p>This step launches the distributed file system Ceph on all nodes.</p>

<p>Finally we can create a new StorageClass which provides block storage for the pods to store data persistently, get <a href="https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/blob/master/storage_rook/rook-storageclass.yaml"><code class="language-plaintext highlighter-rouge">rook-storageclass.yaml</code> from the same repository we used before</a> and execute with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl create -f rook-storageclass.yaml
</code></pre></div></div>

<p>You should now have the rook storageclass available:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl get storageclass
NAME         PROVISIONER
rook-block   rook.io/block
</code></pre></div></div>

<h3 id="optional-test-rook-persistent-storage">(Optional) Test Rook Persistent Storage</h3>

<p>Optionally, we can deploy a simple pod to verify that the storage system is working properly.</p>

<p>You can copy <a href="https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/blob/master/storage_rook/alpine-rook.yaml"><code class="language-plaintext highlighter-rouge">alpine-rook.yaml</code> from Github</a>
and launch it with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl create -f alpine-rook.yaml
</code></pre></div></div>

<p>It is a very small pod with Alpine Linux that creates a 2 GB volume from Rook and mounts it on <code class="language-plaintext highlighter-rouge">/data</code>.</p>

<p>This creates a Pod with Alpine Linux that requests a Persistent Volume Claim to be mounted under <code class="language-plaintext highlighter-rouge">/data</code>. The Persistent Volume Claim specified the type of storage and its size. Once the Pod is created, it asks the Persistent Volume Claim to actually request Rook to prepare a Persistent Volume that is then mounted into the Pod.</p>

<p>We can verify the Persistent Volumes are created and associated with the pod, check:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl get pv
sudo kubectl get pvc
sudo kubectl get logs alpine
</code></pre></div></div>

<p>We can get a shell in the pod with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl exec -it alpine  -- /bin/sh
</code></pre></div></div>

<p>access <code class="language-plaintext highlighter-rouge">/data/</code> and make sure we can write some files.</p>

<p>Once you have completed testing, you can delete the pod and the Persistent Volume Claim with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl delete -f alpine-rook.yaml
</code></pre></div></div>

<p>The Persistent Volume will be automatically deleted by Kubernetes after a few minutes.</p>

<h2 id="setup-https-with-letsencrypt">Setup HTTPS with letsencrypt</h2>

<p>We need <code class="language-plaintext highlighter-rouge">kube-lego</code> to automatically get a HTTPS certificate from Letsencrypt,
For more information see the Ingress section on the <a href="http://zero-to-jupyterhub.readthedocs.io/en/latest/advanced.html">Zero to Jupyterhub Advanced topics</a>.</p>

<p>First we need to customize the Kube Lego configuration, edit the <code class="language-plaintext highlighter-rouge">config_kube-lego_helm.yaml</code> file from the repository and set your email address, then:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo helm install stable/kube-lego --namespace=support --name=lego -f config_kube-lego_helm.yaml
</code></pre></div></div>

<p>Then after you deploy Jupyterhub if you have some HTTPS trouble, you should check the logs of the kube-lego pod. First find the name of the pod with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl get pods -n support
</code></pre></div></div>

<p>Then check its logs:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl logs -n support lego-kube-lego-xxxxx-xxx
</code></pre></div></div>

<h2 id="install-jupyterhub">Install Jupyterhub</h2>

<p>Read all of the documentation of “Zero to Jupyterhub”, then download <a href="https://github.com/zonca/jupyterhub-deploy-kubernetes-jetstream/blob/master/config_jupyterhub_helm.yaml"><code class="language-plaintext highlighter-rouge">config_jupyterhub_helm.yaml</code> from the repository</a> and customize it with the URL of the master node (for Jetstream <code class="language-plaintext highlighter-rouge">js-xxx-xxx.jetstream-cloud.org</code>) and generate the random strings for security, finally run the Helm chart:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
sudo helm repo update
sudo helm install jupyterhub/jupyterhub --version=v0.6 --name=jup \
    --namespace=jup -f config_jupyterhub_helm.yaml
</code></pre></div></div>

<p>Once you modify the configuration you can update the deployment with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo helm upgrade jup jupyterhub/jupyterhub -f config_jupyterhub_helm.yaml
</code></pre></div></div>

<h3 id="test-jupyterhub">Test Jupyterhub</h3>

<p>Connect to the public URL of your master node instance at: <a href="https://js-xxx-xxx.jetstream-cloud.org">https://js-xxx-xxx.jetstream-cloud.org</a></p>

<p>Try to login with your XSEDE username and password and check if Jupyterhub works properly.</p>

<p>If something is wrong, check:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl --namespace=jup get pods
</code></pre></div></div>

<p>Get the name of the <code class="language-plaintext highlighter-rouge">hub</code> pod and check the logs:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl --namespace=jup logs hub-xxxx-xxxxxxx
</code></pre></div></div>

<p>Check that Rook is working properly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl --namespace=jup get pv
sudo kubectl --namespace=jup get pvc
sudo kubectl --namespace=jup describe pvc claim-YOURXSEDEUSERNAME
</code></pre></div></div>

<h2 id="administration-tips">Administration tips</h2>

<h3 id="add-more-servers-to-kubernetes">Add more servers to Kubernetes</h3>

<p>We can create more Ubuntu instances (with a volume attached) and add them to Kubernetes by repeating the same setup we performed on the first worker node.
Once the node joins Kubernetes, it will be automatically used as a node for the distributed filesystem by Rook and be available to host user containers.</p>

<h3 id="remove-a-server-from-kubernetes">Remove a server from Kubernetes</h3>

<p>Launch first the <code class="language-plaintext highlighter-rouge">kubectl drain</code> command to move the currently active pods to other nodes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubectl get nodes
sudo kubectl drain &lt;node name&gt;
</code></pre></div></div>

<p>Then suspend or delete the instance on the Jetstream admin panel.</p>

<h3 id="configure-a-different-authentication-system">Configure a different authentication system</h3>

<p>“Zero to Jupyterhub” supports out of the box authentication with:</p>

<ul>
  <li>XSEDE credentials with CILogon</li>
  <li>Many Campuses credentials with CILogon</li>
  <li>Globus</li>
  <li>Google</li>
</ul>

<p>See <a href="https://zero-to-jupyterhub.readthedocs.io/en/latest/extending-jupyterhub.html#authenticating-with-oauth2">the documentation</a> and modify <code class="language-plaintext highlighter-rouge">config_jupyterhub_helm_v0.5.0.yaml</code> accordingly.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<ul>
  <li>The Jupyter team, in particular Yuvi Panda, for providing a great software platform and a easy-to-user resrouce for deploying it and for direct support in debugging my issues</li>
  <li>XSEDE Extended Collaborative Support Services for supporting part of my time to work on deploying Jupyterhub on Jetstream and providing computational time on Jetstream</li>
  <li>Pacific Research Platform, in particular John Graham, Thomas DeFanti and Dmitry Mishin (SDSC) for access to their Kubernetes platform for testing</li>
  <li>XSEDE Jetstream’s Jeremy Fischer for prompt answers to my questions on Jetstream</li>
</ul>

  </div><a class="u-url" href="/2017/12/scalable-jupyterhub-kubernetes-jetstream.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Tutorials and blog posts by Andrea Zonca: Python, Jupyter, Kubernetes</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/zonca" target="_blank" title="zonca"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/andreazonca" target="_blank" title="andreazonca"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
