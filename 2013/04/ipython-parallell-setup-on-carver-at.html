<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>IPython parallell setup on Carver at NERSC | Andrea Zonca</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="IPython parallell setup on Carver at NERSC" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="IPython parallel is one of the easiest ways to spawn several Python sessions on a Supercomputing cluster and process jobs in parallel. On Carver, the basic setup is running a controller on the login node, and submit engines to the computing nodes via PBS. First create your configuration files running: ipython profile create --parallel Therefore in the ~/.config/ipython/profile_default/ipcluster_config.py, just need to set: c.IPClusterStart.controller_launcher_class = &#39;LocalControllerLauncher&#39; c.IPClusterStart.engine_launcher_class = &#39;PBS&#39; c.PBSLauncher.batch_template_file = u&#39;~/.config/ipython/profile_default/pbs.engine.template&#39; You also need to allow connections to the controller from other hosts, setting  in ~/.config/ipython/profile_default/ipcontroller_config.py: c.HubFactory.ip = &#39;*&#39; With the path to the pbs engine template. Next a couple of examples of pbs templates, for 2 or 8 processes per node: IPython configuration does not seem to be flexible enough to add a parameter for specifying the processes per node. So I just created a bash script that get as parameters the processes per node and the total number of nodes: ipc 8 2 # 2 nodes with 8ppn, 16 total engines ipc 2 3 # 3 nodes with 2ppn, 6 total engines Once the engines are running, jobs can be submitted opening an IPython shell on the login node and run: from IPython.parallel import Client rc = Client() lview = rc.load_balanced_view() # default load-balanced view def serial_func(argument): pass parallel_result = lview.map(serial_func, list_of_arguments) The serial function is sent to the engines and executed for each element of the list of arguments. If the function returns a value, than it is transferred back to the login node. In case the returned values are memory consuming, is also possible to still run the controller on the login node, but execute the interactive IPython session in an interactive job." />
<meta property="og:description" content="IPython parallel is one of the easiest ways to spawn several Python sessions on a Supercomputing cluster and process jobs in parallel. On Carver, the basic setup is running a controller on the login node, and submit engines to the computing nodes via PBS. First create your configuration files running: ipython profile create --parallel Therefore in the ~/.config/ipython/profile_default/ipcluster_config.py, just need to set: c.IPClusterStart.controller_launcher_class = &#39;LocalControllerLauncher&#39; c.IPClusterStart.engine_launcher_class = &#39;PBS&#39; c.PBSLauncher.batch_template_file = u&#39;~/.config/ipython/profile_default/pbs.engine.template&#39; You also need to allow connections to the controller from other hosts, setting  in ~/.config/ipython/profile_default/ipcontroller_config.py: c.HubFactory.ip = &#39;*&#39; With the path to the pbs engine template. Next a couple of examples of pbs templates, for 2 or 8 processes per node: IPython configuration does not seem to be flexible enough to add a parameter for specifying the processes per node. So I just created a bash script that get as parameters the processes per node and the total number of nodes: ipc 8 2 # 2 nodes with 8ppn, 16 total engines ipc 2 3 # 3 nodes with 2ppn, 6 total engines Once the engines are running, jobs can be submitted opening an IPython shell on the login node and run: from IPython.parallel import Client rc = Client() lview = rc.load_balanced_view() # default load-balanced view def serial_func(argument): pass parallel_result = lview.map(serial_func, list_of_arguments) The serial function is sent to the engines and executed for each element of the list of arguments. If the function returns a value, than it is transferred back to the login node. In case the returned values are memory consuming, is also possible to still run the controller on the login node, but execute the interactive IPython session in an interactive job." />
<link rel="canonical" href="https://zonca.dev/2013/04/ipython-parallell-setup-on-carver-at.html" />
<meta property="og:url" content="https://zonca.dev/2013/04/ipython-parallell-setup-on-carver-at.html" />
<meta property="og:site_name" content="Andrea Zonca" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2013-04-11T05:53:00-05:00" />
<script type="application/ld+json">
{"headline":"IPython parallell setup on Carver at NERSC","dateModified":"2013-04-11T05:53:00-05:00","datePublished":"2013-04-11T05:53:00-05:00","url":"https://zonca.dev/2013/04/ipython-parallell-setup-on-carver-at.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zonca.dev/2013/04/ipython-parallell-setup-on-carver-at.html"},"description":"IPython parallel is one of the easiest ways to spawn several Python sessions on a Supercomputing cluster and process jobs in parallel. On Carver, the basic setup is running a controller on the login node, and submit engines to the computing nodes via PBS. First create your configuration files running: ipython profile create --parallel Therefore in the ~/.config/ipython/profile_default/ipcluster_config.py, just need to set: c.IPClusterStart.controller_launcher_class = &#39;LocalControllerLauncher&#39; c.IPClusterStart.engine_launcher_class = &#39;PBS&#39; c.PBSLauncher.batch_template_file = u&#39;~/.config/ipython/profile_default/pbs.engine.template&#39; You also need to allow connections to the controller from other hosts, setting  in ~/.config/ipython/profile_default/ipcontroller_config.py: c.HubFactory.ip = &#39;*&#39; With the path to the pbs engine template. Next a couple of examples of pbs templates, for 2 or 8 processes per node: IPython configuration does not seem to be flexible enough to add a parameter for specifying the processes per node. So I just created a bash script that get as parameters the processes per node and the total number of nodes: ipc 8 2 # 2 nodes with 8ppn, 16 total engines ipc 2 3 # 3 nodes with 2ppn, 6 total engines Once the engines are running, jobs can be submitted opening an IPython shell on the login node and run: from IPython.parallel import Client rc = Client() lview = rc.load_balanced_view() # default load-balanced view def serial_func(argument): pass parallel_result = lview.map(serial_func, list_of_arguments) The serial function is sent to the engines and executed for each element of the list of arguments. If the function returns a value, than it is transferred back to the login node. In case the returned values are memory consuming, is also possible to still run the controller on the login node, but execute the interactive IPython session in an interactive job.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://zonca.dev/feed.xml" title="Andrea Zonca" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Andrea Zonca</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">IPython parallell setup on Carver at NERSC</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2013-04-11T05:53:00-05:00" itemprop="datePublished">
        Apr 11, 2013
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#hpc">hpc</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#supercomputing">supercomputing</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#ipython">ipython</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#python">python</a>
        
      
      </p>
    

        <div class="pb-5 d-flex flex-wrap flex-justify-end">
<div class="px-2">

    <a href="https://github.com/zonca/zonca-blog/tree/master/_posts/2013-04-11-ipython-parallell-setup-on-carver-at.md" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

    </div>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>
 IPython parallel is one of the easiest ways to spawn several Python sessions on a Supercomputing cluster and process jobs in parallel.
 <br />
 <br />
 On Carver, the basic setup is running a controller on the login node, and submit engines to the computing nodes via PBS.
 <br />
 <br />
 <a name="more">
 </a>
 <br />
 First create your configuration files running:
 <br />
 <br />
 <span style="font-family: Courier New, Courier, monospace;">
  ipython profile create --parallel
 </span>
 <br />
 <br />
 Therefore in the ~/.config/ipython/profile_default/ipcluster_config.py, just need to set:
 <br />
 <br />
 <span style="font-family: Courier New, Courier, monospace;">
  c.IPClusterStart.controller_launcher_class = 'LocalControllerLauncher'
 </span>
 <br />
 <span style="font-family: Courier New, Courier, monospace;">
  c.IPClusterStart.engine_launcher_class = 'PBS'
 </span>
 <br />
 <span style="font-family: Courier New, Courier, monospace;">
  c.PBSLauncher.batch_template_file = u'~/.config/ipython/profile_default/pbs.engine.template'
 </span>
 <br />
 <br />
 You also need to allow connections to the controller from other hosts, setting  in ~/.config/ipython/profile_default/ipcontroller_config.py:
 <br />
 <br />
 <span style="font-family: Courier New, Courier, monospace;">
  c.HubFactory.ip = '*'
 </span>
 <br />
</p>
<div>
 <br />
</div>
<p>With the path to the pbs engine template.
<br />
<br />
Next a couple of examples of pbs templates, for 2 or 8 processes per node:
<script src="https://gist.github.com/zonca/5334225.js">
</script>
<br />
IPython configuration does not seem to be flexible enough to add a parameter for specifying the processes per node.
<br />
So I just created a bash script that get as parameters the processes per node and the total number of nodes:
<br />
<br />
<span style="font-family: Courier New, Courier, monospace;">
 ipc 8 2 # 2 nodes with 8ppn, 16 total engines
</span>
<br />
<span style="font-family: Courier New, Courier, monospace;">
 ipc 2 3 # 3 nodes with 2ppn, 6 total engines
</span>
<br />
<br />
<span style="font-family: inherit;">
 Once the engines are running, jobs can be submitted opening an IPython shell on the login node and run:
</span>
<br />
<span style="font-family: inherit;">
 <br />
</span>
<br />
<span style="font-family: Courier New, Courier, monospace;">
 from IPython.parallel import Client
</span>
<br />
<span style="font-family: Courier New, Courier, monospace;">
 rc = Client()
</span>
<br />
<br />
<span style="font-family: Courier New, Courier, monospace;">
 lview = rc.load_balanced_view() # default load-balanced view
</span>
<br /></p>
<div>
 <span style="font-family: Courier New, Courier, monospace;">
  def serial_func(argument):
 </span>
</div>
<div>
 <span style="font-family: Courier New, Courier, monospace;">
  pass
 </span>
</div>
<div>
 <span style="font-family: Courier New, Courier, monospace;">
  parallel_result = lview.map(serial_func, list_of_arguments)
 </span>
</div>
<p><br /></p>
<div style="font-family: inherit;">
 <br />
</div>
<div>
 <span style="font-family: inherit;">
  The serial function is sent to the engines and executed for each element of the list of arguments.
 </span>
</div>
<div>
 <span style="font-family: inherit;">
  If the function returns a value, than it is transferred back to the login node.
 </span>
</div>
<div>
 <span style="font-family: inherit;">
  In case the returned values are memory consuming, is also possible to still run the controller on the login node, but execute the interactive IPython session in an interactive job.
 </span>
</div>
<div style="font-family: inherit;">
 <br />
</div>
<div style="font-family: inherit;">
 <br />
</div>

  </div><a class="u-url" href="/2013/04/ipython-parallell-setup-on-carver-at.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Tutorials and blog posts by Andrea Zonca: Python, Jupyter, Kubernetes</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/zonca" title="zonca"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/andreazonca" title="andreazonca"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
